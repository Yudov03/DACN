# Audio Information Retrieval System

Há»‡ thá»‘ng Truy xuáº¥t ThÃ´ng tin tá»« Ã‚m thanh vÃ  TÃ i liá»‡u sá»­ dá»¥ng ASR (Whisper), Document Processing, Vector Database (Qdrant), LLM (Ollama/OpenAI/Google Gemini), vÃ  Text-to-Speech.

## Kiáº¿n trÃºc

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         INPUT SOURCES                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Audio/Video          â”‚           Documents (68 formats)               â”‚
â”‚   (.mp3, .mp4, .wav)   â”‚   (.pdf, .docx, .xlsx, .pptx, .html, etc.)    â”‚
â”‚         â”‚              â”‚               â”‚                                 â”‚
â”‚         â–¼              â”‚               â–¼                                 â”‚
â”‚   ASR (Whisper)        â”‚     Document Processor                          â”‚
â”‚         â”‚              â”‚     (PDF/DOCX/Excel/OCR)                        â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                        â–¼                                 â”‚
â”‚                              Text Chunking                               â”‚
â”‚                                    â”‚                                     â”‚
â”‚                                    â–¼                                     â”‚
â”‚                    Embedding (SBERT/E5/OpenAI/Google)                    â”‚
â”‚                                    â”‚                                     â”‚
â”‚                                    â–¼                                     â”‚
â”‚                     Vector Database (Qdrant + BM25)                      â”‚
â”‚                                    â”‚                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                         OPTIMIZATIONS                                    â”‚
â”‚   Query Expansion | Context Compression | Caching | Reranking            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                    â–¼                                     â”‚
â”‚                    ENHANCED RAG + ANTI-HALLUCINATION                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚    â”‚  Conflict Detection â†’ Answer Verification â†’ Safe Abstention â”‚      â”‚
â”‚    â”‚  (Date-aware)         (Grounding check)    (Low confidence) â”‚      â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                    â”‚                                     â”‚
â”‚                                    â–¼                                     â”‚
â”‚                          RAG + LLM Generation                            â”‚
â”‚                      (Ollama/GPT/Gemini)                                 â”‚
â”‚                                    â”‚                                     â”‚
â”‚                                    â–¼                                     â”‚
â”‚                         Answer + TTS Output                              â”‚
â”‚                    (Text-to-Speech vá»›i giá»ng Viá»‡t)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Há»— trá»£ nhiá»u providers:**
- **Local**: SBERT/E5 (Embedding) + Ollama (LLM) - Miá»…n phÃ­, offline
- **Google**: Gemini 2.0 Flash + Text Embedding 004
- **OpenAI**: GPT-4o-mini + Text Embedding 3

## Quick Start

### 1. CÃ i Ä‘áº·t

```bash
# Táº¡o virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt
```

### 2. CÃ i Ä‘áº·t Ollama (LLM local - miá»…n phÃ­)

```bash
# Táº£i vÃ  cÃ i Ä‘áº·t tá»«: https://ollama.com/download
# Sau khi cÃ i xong, pull model:
ollama pull llama3.2

# Hoáº·c model tá»‘t hÆ¡n cho tiáº¿ng Viá»‡t:
ollama pull qwen2.5
```

### 3. Cáº¥u hÃ¬nh

```bash
cp .env.example .env
```

Chá»‰nh sá»­a `.env`:

```env
# Option 1: Local (miá»…n phÃ­, offline) - RECOMMENDED
LLM_PROVIDER=ollama
OLLAMA_MODEL=llama3.2
EMBEDDING_PROVIDER=local
LOCAL_EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-mpnet-base-v2

# Option 2: Google Cloud
GOOGLE_API_KEY=your_google_api_key
LLM_PROVIDER=google
EMBEDDING_PROVIDER=google
```

### 4. Import tÃ i liá»‡u

```bash
# Äáº·t tÃ i liá»‡u vÃ o data/resource/

# === Option A: All-in-One (Recommended) ===
python scripts/import_resources.py              # Import táº¥t cáº£
python scripts/import_resources.py --clear      # XÃ³a vÃ  import láº¡i
python scripts/import_resources.py --dry-run    # Xem trÆ°á»›c

# === Option B: Two-Step (Advanced) ===
python scripts/process_resources.py             # Step 1: Process OCR/ASR
python scripts/reindex_documents.py             # Step 2: Index to Qdrant
python scripts/reindex_documents.py --file doc_id  # Re-index single file
```

**Two-Step workflow** há»¯u Ã­ch khi:
- Thay Ä‘á»•i embedding/chunking config â†’ chá»‰ cáº§n cháº¡y `reindex_documents.py --reset`
- Debug OCR/ASR â†’ kiá»ƒm tra `data/knowledge_base/processed/`
- Re-index má»™t file â†’ `reindex_documents.py --file doc_id`

### 5. Cháº¡y á»©ng dá»¥ng

```bash
# Web UI cho sinh viÃªn (tá»± Ä‘á»™ng start Ollama)
streamlit run app.py

# CLI interactive mode
python main.py --mode interactive
```

**Features (app.py - Student Portal):**
- ğŸ’¬ **Chat**: Há»i Ä‘Ã¡p vá»›i Knowledge Base
- ğŸ” **Search**: TÃ¬m kiáº¿m semantic
- ğŸ“š **Sources**: Hiá»ƒn thá»‹ nguá»“n tham kháº£o
- ğŸ”Š **TTS**: Text-to-Speech (Vietnamese)
- âš¡ **Auto-start**: Tá»± Ä‘á»™ng khá»Ÿi Ä‘á»™ng Ollama server

## Cáº¥u trÃºc thÆ° má»¥c

```
CODE/
â”œâ”€â”€ main.py                 # Entry point (CLI)
â”œâ”€â”€ app.py                  # DocChat Platform (Web UI)
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ .env.example            # Config template
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py           # System config
â”‚   â””â”€â”€ modules/
â”‚       â”‚  # Core Modules
â”‚       â”œâ”€â”€ asr_module.py               # Whisper ASR
â”‚       â”œâ”€â”€ chunking_module.py          # Text Splitter
â”‚       â”œâ”€â”€ embedding_module.py         # SBERT/E5/OpenAI/Google
â”‚       â”œâ”€â”€ vector_db_module.py         # Qdrant + BM25 Hybrid
â”‚       â”œâ”€â”€ rag_module.py               # Enhanced RAG
â”‚       â”œâ”€â”€ reranker_module.py          # Cross-Encoder Reranking
â”‚       â”œâ”€â”€ evaluation_module.py        # Metrics
â”‚       â”‚
â”‚       â”‚  # Anti-Hallucination Modules
â”‚       â”œâ”€â”€ answer_verification.py      # Grounding check + abstention
â”‚       â”œâ”€â”€ conflict_detection.py       # Date-aware conflict resolution
â”‚       â”‚
â”‚       â”‚  # Document Processing (34 formats)
â”‚       â”œâ”€â”€ document_processor/
â”‚       â”‚   â”œâ”€â”€ base.py                 # Base processor classes
â”‚       â”‚   â”œâ”€â”€ pdf_processor.py        # PDF extraction + OCR
â”‚       â”‚   â”œâ”€â”€ docx_processor.py       # Word document processor
â”‚       â”‚   â”œâ”€â”€ excel_processor.py      # Excel spreadsheets
â”‚       â”‚   â”œâ”€â”€ pptx_processor.py       # PowerPoint presentations
â”‚       â”‚   â”œâ”€â”€ text_processor.py       # Plain text processor
â”‚       â”‚   â”œâ”€â”€ audio_processor.py      # Audio files (Whisper)
â”‚       â”‚   â”œâ”€â”€ video_processor.py      # Video files (FFmpeg)
â”‚       â”‚   â””â”€â”€ unified_processor.py    # Auto-detect processor
â”‚       â”‚
â”‚       â”‚  # Knowledge Base
â”‚       â”œâ”€â”€ knowledge_base.py           # Document management
â”‚       â”‚
â”‚       â”‚  # Text-to-Speech
â”‚       â”œâ”€â”€ tts_module.py               # TTS with edge-tts
â”‚       â”‚
â”‚       â”‚  # Optimization Modules
â”‚       â”œâ”€â”€ query_expansion_module.py       # Query Expansion
â”‚       â”œâ”€â”€ context_compression_module.py   # Context Compression
â”‚       â”œâ”€â”€ caching_module.py               # Embedding/Response Cache
â”‚       â””â”€â”€ prompt_templates.py             # RAG Prompts (9 templates)
â”‚
â”œâ”€â”€ scripts/                # Admin + Demo scripts
â”‚   â”œâ”€â”€ import_resources.py         # All-in-one import
â”‚   â”œâ”€â”€ process_resources.py        # Step 1: Process OCR/ASR
â”‚   â”œâ”€â”€ reindex_documents.py        # Step 2: Index to Qdrant
â”‚   â”œâ”€â”€ demo_rag_pipeline.py        # RAG pipeline demo
â”‚   â”œâ”€â”€ demo_document_processor.py  # Document processing demo
â”‚   â””â”€â”€ demo_anti_hallucination.py  # Anti-hallucination demo
â”‚
â”œâ”€â”€ evaluation/             # System evaluation
â”‚   â”œâ”€â”€ datasets/           # Test datasets (Vietnamese, SQuAD)
â”‚   â”œâ”€â”€ scripts/            # Evaluation scripts
â”‚   â”‚   â”œâ”€â”€ evaluate_system.py          # Basic evaluation
â”‚   â”‚   â”œâ”€â”€ evaluate_real_datasets.py   # Real datasets evaluation
â”‚   â”‚   â”œâ”€â”€ run_benchmark.py            # Full benchmark
â”‚   â”‚   â”œâ”€â”€ run_evaluation.py           # Quick/full evaluation
â”‚   â”‚   â”œâ”€â”€ tune_parameters.py          # Parameter tuning
â”‚   â”‚   â””â”€â”€ download_dataset.py         # Dataset downloader
â”‚   â”œâ”€â”€ results/            # Evaluation results
â”‚   â”œâ”€â”€ benchmark_results/  # Benchmark results
â”‚   â””â”€â”€ tuning_results/     # Parameter tuning results
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py         # Pytest fixtures
â”‚   â”œâ”€â”€ run_tests.py        # Test runner script
â”‚   â”œâ”€â”€ test_unit.py        # Unit tests (43 tests)
â”‚   â”œâ”€â”€ test_integration.py # Integration tests (12 tests)
â”‚   â”œâ”€â”€ test_e2e.py         # E2E tests (9 tests)
â”‚   â””â”€â”€ test_data/          # Test data files
â”‚
â””â”€â”€ data/                   # Runtime data storage
    â”œâ”€â”€ resource/           # INPUT: Upload documents here
    â”‚   â”œâ”€â”€ documents/      # PDF, DOCX, XLSX, Images, Code...
    â”‚   â””â”€â”€ audio/          # MP3, WAV, MP4, AVI...
    â”œâ”€â”€ knowledge_base/     # PROCESSED: System-managed
    â”‚   â”œâ”€â”€ index.json      # Document registry
    â”‚   â”œâ”€â”€ documents/      # Copied files
    â”‚   â”œâ”€â”€ transcripts/    # ASR output
    â”‚   â””â”€â”€ processed/      # Processed JSON (RAW content)
    â””â”€â”€ cache/              # CACHE: Post-processing cache
        â””â”€â”€ post_processing/
```

## Modules

### Core Modules

#### 1. ASR Module - Whisper
```python
from src.modules import WhisperASR

asr = WhisperASR(model_name="base")  # tiny, base, small, medium, large
transcript = asr.transcribe_audio("audio.mp3")
```

#### 2. Embedding Module - Local/Cloud
```python
from src.modules import TextEmbedding

# Local (recommended)
embedder = TextEmbedding(provider="local", model_name="e5")

# Cloud
embedder = TextEmbedding(provider="google")
embeddings = embedder.encode_chunks(chunks)
```

#### 3. Vector Database - Qdrant + Hybrid Search
```python
from src.modules import VectorDatabase

vector_db = VectorDatabase(collection_name="transcripts", embedding_dimension=768)

# Hybrid search (Vector + BM25)
results = vector_db.hybrid_search(
    query="machine learning",
    query_embedding=emb,
    alpha=0.7,  # 0.7 vector + 0.3 BM25
    top_k=5
)
```

#### 4. RAG Module - Ollama/GPT/Gemini
```python
from src.modules import RAGSystem

rag = RAGSystem(
    vector_db=vector_db,
    embedder=embedder,
    provider="ollama",  # or google, openai
)
response = rag.query("Ná»™i dung chÃ­nh lÃ  gÃ¬?")
```

#### 5. Reranker Module
```python
from src.modules import CrossEncoderReranker

reranker = CrossEncoderReranker()
results = vector_db.search_with_rerank(query, emb, reranker, top_k=5)
```

### Anti-Hallucination Modules

#### 6. Answer Verification
```python
from src.modules import AnswerVerifier, AbstentionChecker

# Verify answer is grounded in context
verifier = AnswerVerifier()
result = verifier.verify(
    answer="Há»c phÃ­ lÃ  15 triá»‡u",
    context="Há»c phÃ­ nÄƒm 2024 lÃ  15 triá»‡u Ä‘á»“ng/ká»³",
    question="Há»c phÃ­ bao nhiÃªu?"
)

print(result.grounding_level)    # FULLY_GROUNDED / PARTIALLY_GROUNDED / LIKELY_HALLUCINATED
print(result.confidence_score)   # 0.0 - 1.0
print(result.explanation)        # Chi tiáº¿t Ä‘Ã¡nh giÃ¡

# Check if should abstain from answering
checker = AbstentionChecker(min_retrieval_score=0.5)
should_abstain, reason = checker.should_abstain(
    question="Äiá»ƒm thi IELTS?",
    retrieved_contexts=[{"similarity": 0.3}]  # Low relevance
)
# should_abstain = True, reason = "No relevant context found"
```

**Grounding Levels:**
| Level | Description |
|-------|-------------|
| FULLY_GROUNDED | Táº¥t cáº£ claims cÃ³ trong context |
| PARTIALLY_GROUNDED | Má»™t sá»‘ claims cÃ³ trong context |
| LIKELY_HALLUCINATED | Claims khÃ´ng cÃ³ trong context |

#### 7. Conflict Detection
```python
from src.modules import ConflictDetector

detector = ConflictDetector()

# Detect conflicts between chunks
chunks = [
    {"text": "Há»c phÃ­ 2023: 15 triá»‡u", "metadata": {"date": "2023-01-01"}},
    {"text": "Há»c phÃ­ 2024: 18 triá»‡u (má»›i)", "metadata": {"date": "2024-01-01"}},
]

result = detector.detect_and_resolve(chunks, "há»c phÃ­")

print(result.has_conflicts)       # True
print(result.conflict_summary)    # "Found version conflicts"
print(result.recommended_chunks)  # Chunks má»›i nháº¥t Ä‘Æ°á»£c Æ°u tiÃªn
print(result.resolution_note)     # "Using latest information from 2024"
```

**Conflict Types:**
| Type | Detection |
|------|-----------|
| Date/Version | Æ¯u tiÃªn thÃ´ng tin má»›i nháº¥t |
| Numeric | So sÃ¡nh giÃ¡ trá»‹ sá»‘ |
| Semantic | PhÃ¡t hiá»‡n mÃ¢u thuáº«n ngá»¯ nghÄ©a |

### Document Processing Modules

#### 8. Document Processor - 34 Formats
```python
from src.modules import UnifiedProcessor

# Auto-detect vÃ  xá»­ lÃ½ document
processor = UnifiedProcessor()
doc = processor.process("document.pdf")

print(doc.content)       # Extracted text
print(doc.chunks)        # Text chunks vá»›i metadata
print(doc.tables)        # Extracted tables (PDF)
print(doc.metadata)      # Document metadata
```

**Supported formats (68 extensions):**

| Category | Formats |
|----------|---------|
| **Documents** | .pdf, .docx, .doc |
| **Presentations** | .pptx, .ppt |
| **Spreadsheets** | .xlsx, .xls |
| **Text/Data** | .txt, .md, .csv, .tsv, .json, .xml, .html, .log, .ini, .cfg, .rtf |
| **Code** | .py, .js, .ts, .jsx, .tsx, .java, .kt, .cpp, .c, .h, .hpp, .go, .rs, .rb, .php, .swift, .cs, .vb, .sql, .sh, .bash, .ps1, .yaml, .yml, .toml, .r, .R, .scala |
| **Audio** | .mp3, .wav, .m4a, .flac, .ogg, .wma, .aac |
| **Video** | .mp4, .avi, .mkv, .mov, .wmv, .flv, .webm, .m4v |
| **Images (OCR)** | .png, .jpg, .jpeg, .bmp, .tiff, .tif, .webp |

**Audio/Video Processing vá»›i timestamps:**
```python
from src.modules import UnifiedProcessor, format_transcript_with_timestamps

processor = UnifiedProcessor()

# Process video lecture
doc = processor.process("lecture.mp4")

# Get transcript with timestamps
for chunk in doc.chunks:
    start = chunk.metadata.get("start_time", 0)
    end = chunk.metadata.get("end_time", 0)
    print(f"[{start:.1f}s - {end:.1f}s] {chunk.text}")

# Or use helper function
print(format_transcript_with_timestamps(doc.chunks))

# Metadata includes duration, resolution, etc.
print(doc.metadata.extra)
# {'duration_seconds': 3600, 'resolution': '1920x1080', ...}
```

#### 9. Knowledge Base - Document Management
```python
from src.modules import KnowledgeBase

# Táº¡o Knowledge Base
kb = KnowledgeBase(base_dir="./kb_data")

# ThÃªm document
doc_id = kb.add_document("report.pdf", tags=["report", "2024"])

# TÃ¬m kiáº¿m (by filename/tags)
results = kb.search_documents("report")

# Semantic search (by content)
results = kb.semantic_search("machine learning applications", top_k=5)

# Export/Import
kb.export_kb("backup.zip")
kb.import_kb("backup.zip")

# Statistics
stats = kb.get_stats()
print(f"Documents: {stats.total_documents}")
print(f"Chunks: {stats.total_chunks}")
```

#### 10. Text-to-Speech (TTS) Module
```python
from src.modules import TextToSpeech, text_to_speech

# Simple function
audio_path = text_to_speech("Xin chÃ o!", voice="vi-female")

# Full control vá»›i class
tts = TextToSpeech(voice="vi-female")
tts.set_rate("+10%")  # Faster
tts.set_volume("+20%")

# Synchronous synthesis
audio_bytes = tts.synthesize_sync("Ná»™i dung cáº§n Ä‘á»c")

# Async synthesis (for streaming)
import asyncio
audio = asyncio.run(tts.synthesize("Async text"))

# Save to file
tts.save_to_file("output.mp3", "Text content")
```

**Available voices:**
| Voice | Language | Gender |
|-------|----------|--------|
| vi-female | Vietnamese | Female |
| vi-male | Vietnamese | Male |
| en-female | English | Female |
| en-male | English | Male |

### Optimization Modules

#### 11. Query Expansion
```python
from src.modules import QueryExpander, MultiQueryRetriever

# Expand query vá»›i synonyms
expander = QueryExpander(method="synonym")
queries = expander.expand("AI lÃ  gÃ¬?")
# ['AI lÃ  gÃ¬?', 'trÃ­ tuá»‡ nhÃ¢n táº¡o lÃ  gÃ¬?', ...]

# Multi-query retrieval vá»›i RRF fusion
retriever = MultiQueryRetriever(vector_db, embedder, expander)
results = retriever.retrieve(query, top_k=5, fusion_method="rrf")
```

#### 12. Context Compression
```python
from src.modules import ContextCompressor

# NÃ©n context giáº£m 60-75% tokens
compressor = ContextCompressor(method="extractive", max_tokens=500)
compressed, chunks = compressor.compress(query, contexts)
```

#### 13. Caching
```python
from src.modules import CacheManager

cache = CacheManager(cache_dir="./cache")

# Cache embeddings (~0.01ms per hit)
cache.set_embedding("text", "model", embedding)
cached = cache.get_embedding("text", "model")

# Cache LLM responses
cache.set_response(prompt, model, response)
```

#### 14. Prompt Templates (9 Templates)
```python
from src.modules import PromptTemplateManager

manager = PromptTemplateManager(language="vi")

# List available templates
templates = manager.list_templates()
# ['basic_qa', 'audio_qa', 'factual_qa', 'cot_qa',
#  'strict_qa', 'citation_required', 'conflict_aware',
#  'safe_abstention', 'summarize']

sys_prompt, user_prompt = manager.format_prompt(
    "strict_qa",  # Anti-hallucination template
    context=context,
    question=question
)
```

**Available Templates:**
| Template | Use Case |
|----------|----------|
| basic_qa | General Q&A |
| audio_qa | Audio transcripts with timestamps |
| factual_qa | Factual questions |
| cot_qa | Chain-of-thought reasoning |
| **strict_qa** | **Anti-hallucination (only answer from context)** |
| **citation_required** | **Must cite sources** |
| **conflict_aware** | **Handle conflicting information** |
| **safe_abstention** | **Say "I don't know" when uncertain** |
| summarize | Document summarization |

## Evaluation

### Run Evaluation

```bash
# Quick evaluation
python evaluation/scripts/run_evaluation.py --mode quick

# Evaluate vá»›i datasets thá»±c táº¿
python evaluation/scripts/evaluate_real_datasets.py --dataset all --embedding e5 --save

# Full benchmark
python evaluation/scripts/run_benchmark.py --dataset vietnamese

# Parameter tuning
python evaluation/scripts/tune_parameters.py --method random --iterations 20

# Demo optimization modules
python scripts/demo_optimizations.py
```

See `evaluation/README.md` for more details.

### Results

#### Embedding Model Comparison
| Model | MRR | NDCG@5 | Latency |
|-------|-----|--------|---------|
| SBERT | 0.72 | 0.68 | 45ms |
| E5 | 0.89 | 0.85 | 52ms |
| E5-large | 0.91 | 0.87 | 78ms |

#### Search Method Comparison
| Method | MRR | Notes |
|--------|-----|-------|
| Vector only | 0.85 | Good for semantic |
| BM25 only | 0.78 | Good for keywords |
| Hybrid (0.7) | 0.89 | Best overall |
| + Reranking | 0.92 | Best quality |

## Cáº¥u hÃ¬nh

### Models

| Type | Provider | Model | Dimensions |
|------|----------|-------|------------|
| Embedding | Local | SBERT | 768 |
| Embedding | Local | E5 | 768 |
| Embedding | Google | text-embedding-004 | 768 |
| Embedding | OpenAI | text-embedding-3-small | 1536 |
| LLM | Local | Ollama (qwen2.5) | - |
| LLM | Google | gemini-2.0-flash | - |
| LLM | OpenAI | gpt-4o-mini | - |

### Environment Variables

Táº¥t cáº£ cáº¥u hÃ¬nh Ä‘Æ°á»£c Ä‘á»c tá»« file `.env`:

```env
# === Provider Selection ===
LLM_PROVIDER=ollama              # ollama, google, openai
EMBEDDING_PROVIDER=local         # local, google, openai

# === Ollama (Local LLM) ===
OLLAMA_MODEL=llama3.2            # llama3.2, qwen2.5, mistral, etc.
OLLAMA_BASE_URL=http://localhost:11434

# === Local Embedding ===
LOCAL_EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-mpnet-base-v2
LOCAL_EMBEDDING_DIMENSION=768
LOCAL_EMBEDDING_DEVICE=cuda      # cuda, cpu, or auto-detect

# === Cloud API Keys (optional) ===
GOOGLE_API_KEY=your_key
OPENAI_API_KEY=your_key

# === Qdrant Vector Database ===
QDRANT_HOST=localhost
QDRANT_PORT=6333
COLLECTION_NAME=knowledge_base

# === Whisper ASR ===
WHISPER_MODEL=base               # tiny, base, small, medium, large
WHISPER_DEVICE=cuda              # cuda or cpu

# === Chunking ===
CHUNK_SIZE=500
CHUNK_OVERLAP=50
CHUNKING_METHOD=semantic         # semantic, recursive, fixed, sentence
SEMANTIC_THRESHOLD=0.65
SEMANTIC_WINDOW_SIZE=5

# === RAG Parameters ===
TOP_K=5
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=500
```

**LÆ°u Ã½:** App tá»± Ä‘á»™ng Ä‘á»c tá»« `.env`, khÃ´ng cáº§n sá»­a code khi thay Ä‘á»•i cáº¥u hÃ¬nh.

## Testing

```bash
# Cháº¡y táº¥t cáº£ tests
python tests/run_tests.py              # All tests (unit + integration + e2e)
python tests/run_tests.py quick        # Quick unit tests only

# Hoáº·c dÃ¹ng pytest
pytest tests/ -v                       # All tests
pytest tests/test_unit.py -v           # Unit tests (43 tests)
pytest tests/test_integration.py -v    # Integration tests (12 tests)
pytest tests/test_e2e.py -v            # E2E tests (9 tests)
```

### Test Structure

```
tests/
â”œâ”€â”€ conftest.py          # Pytest fixtures
â”œâ”€â”€ run_tests.py         # Test runner script
â”œâ”€â”€ test_unit.py         # Unit tests (43 tests) - Individual modules
â”œâ”€â”€ test_integration.py  # Integration tests (12 tests) - Pipelines
â”œâ”€â”€ test_e2e.py          # E2E tests (9 tests) - Full workflows
â””â”€â”€ test_data/           # Test data files
```

| Test File | Tests | Description |
|-----------|-------|-------------|
| `test_unit.py` | **43** | Unit tests cho tá»«ng module riÃªng láº» |
| `test_integration.py` | **12** | Integration tests cho pipelines |
| `test_e2e.py` | **9** | End-to-end tests cho full workflows |

### Test Coverage (64 Tests)

**Unit Tests (43):**
- âœ… Chunking (fixed, sentence, recursive)
- âœ… Embedding (local SBERT/E5, similarity)
- âœ… VectorDB (init, add, search, stats)
- âœ… Document Processor (34 formats)
- âœ… Knowledge Base (init, add, stats)
- âœ… TTS (voices, synthesis, settings)
- âœ… Answer Verification (grounding, abstention)
- âœ… Conflict Detection (date extraction)
- âœ… Prompt Templates (9 templates)
- âœ… RAG (enhanced features)

**Integration Tests (12):**
- âœ… Chunking â†’ Embedding pipeline
- âœ… Embedding â†’ VectorDB pipeline
- âœ… Full retrieval pipeline
- âœ… Document â†’ KB pipeline
- âœ… Anti-hallucination pipeline
- âœ… TTS integration
- âœ… Prompt integration

**E2E Tests (9):**
- âœ… Document to Answer flow
- âœ… Knowledge Base workflow
- âœ… Anti-hallucination workflow
- âœ… TTS output workflow
- âœ… Multi-format workflow
- âœ… System health check

## Troubleshooting

| Lá»—i | Giáº£i phÃ¡p |
|-----|-----------|
| `Ollama connection refused` | App tá»± Ä‘á»™ng start Ollama. Náº¿u khÃ´ng Ä‘Æ°á»£c: cÃ i Ollama tá»« https://ollama.com/download rá»“i cháº¡y `ollama pull llama3.2` |
| `API_KEY chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh` | ThÃªm key vÃ o `.env` hoáº·c dÃ¹ng local models (recommended) |
| `CUDA out of memory` | Äá»•i `WHISPER_MODEL=tiny` trong `.env` |
| `UnicodeEncodeError` | Cháº¡y `chcp 65001` trÆ°á»›c khi cháº¡y script |
| `429 Rate limit exceeded` | Äá»£i 1 phÃºt hoáº·c dÃ¹ng local models |
| `FFmpeg not found` | CÃ i FFmpeg: `winget install ffmpeg` (Windows) hoáº·c `brew install ffmpeg` (Mac). Restart terminal. |
| `Video processing slow` | DÃ¹ng `WHISPER_MODEL=tiny` hoáº·c `base` |
| `I/O operation on closed file` | Streamlit bug - Ä‘Ã£ Ä‘Æ°á»£c fix trong app.py |
| `torch.classes warning` | Warning vÃ´ háº¡i, Ä‘Ã£ Ä‘Æ°á»£c suppress |
| `OCR khÃ´ng chÃ­nh xÃ¡c` | DÃ¹ng PDF digital thay vÃ¬ scan, hoáº·c áº£nh cháº¥t lÆ°á»£ng cao |

## Tech Stack

- **ASR**: OpenAI Whisper (Audio/Video transcription)
- **Document Processing**: PyMuPDF, python-docx, EasyOCR, pdfplumber, openpyxl, python-pptx
- **Video Processing**: FFmpeg (audio extraction), moviepy (fallback)
- **Embedding**: Sentence-BERT, E5, OpenAI, Google
- **Vector DB**: Qdrant + BM25 Hybrid
- **LLM**: Ollama, OpenAI GPT, Google Gemini
- **Reranking**: Cross-Encoder (sentence-transformers)
- **Anti-Hallucination**: Answer Verification, Conflict Detection, Safe Abstention
- **TTS**: edge-tts (Vietnamese + English voices)
- **Optimization**: Query Expansion, Context Compression, Caching, Prompt Templates
- **Evaluation**: MRR, NDCG, Precision, Recall, F1, BLEU
- **Web UI**: Streamlit
- **Testing**: pytest, comprehensive test suite (64 tests)

## License

MIT License

---

**Äá»“ Ã¡n chuyÃªn ngÃ nh - 2025**
