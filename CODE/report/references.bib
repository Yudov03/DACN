% ===== Automatic Speech Recognition =====
@article{whisper2023,
    author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
    title = {Robust Speech Recognition via Large-Scale Weak Supervision},
    journal = {Proceedings of the 40th International Conference on Machine Learning},
    year = {2023},
    pages = {28492--28518},
    publisher = {PMLR}
}

@misc{faster_whisper,
    author = {SYSTRAN},
    title = {Faster-Whisper: Reimplementation of {OpenAI's Whisper} model using {CTranslate2}},
    howpublished = {\url{https://github.com/SYSTRAN/faster-whisper}},
    note = {Truy c\d{a}p: 15/12/2024}
}

@inproceedings{silero_vad,
    author = {Silero Team},
    title = {Silero {VAD}: pre-trained enterprise-grade Voice Activity Detector},
    booktitle = {GitHub Repository},
    year = {2021},
    howpublished = {\url{https://github.com/snakers4/silero-vad}}
}

% ===== Large Language Models =====
@article{vaswani2017attention,
    author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
    title = {Attention is All You Need},
    journal = {Advances in Neural Information Processing Systems},
    volume = {30},
    year = {2017}
}

@article{devlin2018bert,
    author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
    title = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    journal = {arXiv preprint arXiv:1810.04805},
    year = {2018}
}

@article{brown2020language,
    author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and others},
    title = {Language Models are Few-Shot Learners},
    journal = {Advances in Neural Information Processing Systems},
    volume = {33},
    pages = {1877--1901},
    year = {2020}
}

@misc{touvron2023llama,
    author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and others},
    title = {{LLaMA}: Open and Efficient Foundation Language Models},
    year = {2023},
    howpublished = {arXiv preprint arXiv:2302.13971}
}

@misc{qwen2024,
    author = {Alibaba Cloud},
    title = {{Qwen2.5}: A Large Language Model Series},
    howpublished = {\url{https://qwenlm.github.io/blog/qwen2.5/}},
    year = {2024},
    note = {Truy c\d{a}p: 15/12/2024}
}

@misc{ollama,
    author = {Ollama},
    title = {Ollama - Run Large Language Models Locally},
    howpublished = {\url{https://ollama.com}},
    note = {Truy c\d{a}p: 15/12/2024}
}

@misc{gemini2024,
    author = {Google DeepMind},
    title = {Gemini: A Family of Highly Capable Multimodal Models},
    year = {2024},
    howpublished = {\url{https://deepmind.google/technologies/gemini/}}
}

% ===== Retrieval-Augmented Generation =====
@article{lewis2020rag,
    author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
    title = {Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks},
    journal = {Advances in Neural Information Processing Systems},
    volume = {33},
    pages = {9459--9474},
    year = {2020}
}

@article{gao2023rag_survey,
    author = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Haofen},
    title = {Retrieval-Augmented Generation for Large Language Models: A Survey},
    journal = {arXiv preprint arXiv:2312.10997},
    year = {2023}
}

@article{izacard2022few,
    author = {Izacard, Gautier and Lewis, Patrick and Lomeli, Maria and Hosseini, Lucas and Petroni, Fabio and Schick, Timo and Dwivedi-Yu, Jane and Joulin, Armand and Riedel, Sebastian and Grave, Edouard},
    title = {Few-shot Learning with Retrieval Augmented Language Models},
    journal = {arXiv preprint arXiv:2208.03299},
    year = {2022}
}

% ===== Vector Databases and Embeddings =====
@misc{qdrant,
    author = {Qdrant},
    title = {Qdrant - Vector Database for the Next Generation of {AI} Applications},
    howpublished = {\url{https://qdrant.tech}},
    note = {Truy c\d{a}p: 15/12/2024}
}

@article{reimers2019sentence,
    author = {Reimers, Nils and Gurevych, Iryna},
    title = {Sentence-{BERT}: Sentence Embeddings using Siamese {BERT}-Networks},
    journal = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing},
    year = {2019}
}

@article{wang2022e5,
    author = {Wang, Liang and Yang, Nan and Huang, Xiaolong and Jiao, Binxing and Yang, Linjun and Jiang, Daxin and Majumder, Rangan and Wei, Furu},
    title = {Text Embeddings by Weakly-Supervised Contrastive Pre-training},
    journal = {arXiv preprint arXiv:2212.03533},
    year = {2022}
}

@article{johnson2019faiss,
    author = {Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
    title = {Billion-scale similarity search with {GPUs}},
    journal = {IEEE Transactions on Big Data},
    volume = {7},
    number = {3},
    pages = {535--547},
    year = {2019}
}

% ===== OCR and Document Processing =====
@misc{paddleocr,
    author = {PaddlePaddle},
    title = {{PaddleOCR}: Awesome multilingual {OCR} toolkits},
    howpublished = {\url{https://github.com/PaddlePaddle/PaddleOCR}},
    note = {Truy c\d{a}p: 15/12/2024}
}

@misc{pymupdf,
    author = {Artifex Software},
    title = {{PyMuPDF}: Python bindings for {MuPDF}},
    howpublished = {\url{https://pymupdf.readthedocs.io/}},
    note = {Truy c\d{a}p: 15/12/2024}
}

% ===== Information Retrieval =====
@book{manning2008ir,
    author = {Manning, Christopher D and Raghavan, Prabhakar and Sch{\"u}tze, Hinrich},
    title = {Introduction to Information Retrieval},
    publisher = {Cambridge University Press},
    year = {2008}
}

@article{robertson2009bm25,
    author = {Robertson, Stephen and Zaragoza, Hugo},
    title = {The Probabilistic Relevance Framework: {BM25} and Beyond},
    journal = {Foundations and Trends in Information Retrieval},
    volume = {3},
    number = {4},
    pages = {333--389},
    year = {2009}
}

@article{cormack1998reciprocal,
    author = {Cormack, Gordon V and Clarke, Charles LA and Buettcher, Stefan},
    title = {Reciprocal Rank Fusion Outperforms Condorcet and Individual Rank Learning Methods},
    journal = {Proceedings of the 32nd International ACM SIGIR Conference},
    pages = {758--759},
    year = {2009}
}

% ===== Anti-Hallucination and Grounding =====
@article{ji2023hallucination,
    author = {Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
    title = {Survey of Hallucination in Natural Language Generation},
    journal = {ACM Computing Surveys},
    volume = {55},
    number = {12},
    pages = {1--38},
    year = {2023}
}

@article{zhang2023siren,
    author = {Zhang, Yue and Li, Yafu and Cui, Leyang and Cai, Deng and Liu, Lemao and Fu, Tingchen and Huang, Xinting and Zhao, Enbo and Zhang, Yu and Chen, Yulong and others},
    title = {Siren's Song in the {AI} Ocean: A Survey on Hallucination in Large Language Models},
    journal = {arXiv preprint arXiv:2309.01219},
    year = {2023}
}

@article{mialon2023augmented,
    author = {Mialon, Gr{\'e}goire and Dess{\`\i}, Roberto and Lomeli, Maria and Nalmpantis, Christoforos and Pasunuru, Ram and Raileanu, Roberta and Rozi{\`e}re, Baptiste and Schick, Timo and Dwivedi-Yu, Jane and Celikyilmaz, Asli and others},
    title = {Augmented Language Models: a Survey},
    journal = {arXiv preprint arXiv:2302.07842},
    year = {2023}
}

% ===== Text-to-Speech =====
@misc{edge_tts,
    author = {Microsoft},
    title = {Microsoft Edge Text-to-Speech},
    howpublished = {\url{https://github.com/rany2/edge-tts}},
    note = {Truy c\d{a}p: 15/12/2024}
}

% ===== Chunking and Text Processing =====
@misc{langchain_chunking,
    author = {LangChain},
    title = {Text Splitters Documentation},
    howpublished = {\url{https://python.langchain.com/docs/modules/data_connection/document_transformers/}},
    year = {2024},
    note = {Truy c\d{a}p: 15/12/2024}
}

% ===== Evaluation Metrics =====
@article{voorhees2000mrr,
    author = {Voorhees, Ellen M},
    title = {The {TREC-8} Question Answering Track Report},
    journal = {TREC},
    volume = {99},
    pages = {77--82},
    year = {1999}
}

@article{jarvelin2002ndcg,
    author = {J{\"a}rvelin, Kalervo and Kek{\"a}l{\"a}inen, Jaana},
    title = {Cumulated Gain-Based Evaluation of {IR} Techniques},
    journal = {ACM Transactions on Information Systems},
    volume = {20},
    number = {4},
    pages = {422--446},
    year = {2002}
}

% ===== Web Framework =====
@misc{streamlit,
    author = {Streamlit Inc},
    title = {Streamlit - The fastest way to build data apps},
    howpublished = {\url{https://streamlit.io}},
    note = {Truy c\d{a}p: 15/12/2024}
}

@misc{python,
    author = {{Python Software Foundation}},
    title = {Python Programming Language},
    howpublished = {\url{https://www.python.org}},
    note = {Truy c\d{a}p: 15/12/2024}
}

% ===== Data Management =====
@article{halevy2009unreasonable,
    author = {Halevy, Alon and Norvig, Peter and Pereira, Fernando},
    title = {The Unreasonable Effectiveness of Data},
    journal = {IEEE Intelligent Systems},
    volume = {24},
    number = {2},
    pages = {8--12},
    year = {2009},
    publisher = {IEEE}
}

% ===== Education and Learning =====
@article{heilesen2010lecture,
    author = {Heilesen, Simon B.},
    title = {What is the academic efficacy of podcasting?},
    journal = {Computers \& Education},
    volume = {55},
    number = {3},
    pages = {1063--1068},
    year = {2010},
    publisher = {Elsevier}
}

@article{chi2014icap,
    author = {Chi, Michelene T. H. and Wylie, Ruth},
    title = {The {ICAP} Framework: Linking Cognitive Engagement to Active Learning Outcomes},
    journal = {Educational Psychologist},
    volume = {49},
    number = {4},
    pages = {219--243},
    year = {2014},
    publisher = {Taylor \& Francis}
}

% ===== Vietnamese NLP =====
@inproceedings{phobert,
    author = {Nguyen, Dat Quoc and Nguyen, Anh Tuan},
    title = {{PhoBERT}: Pre-trained language models for {Vietnamese}},
    booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2020},
    pages = {1037--1042},
    year = {2020}
}

@article{vietnamese_asr,
    author = {Nguyen, Van Hai and Luong, Chi Mai and Vu, Hai Quan},
    title = {Vietnamese Speech Recognition: A Survey},
    journal = {Journal of Computer Science and Cybernetics},
    volume = {36},
    number = {4},
    pages = {293--312},
    year = {2020}
}

% ===== Cross-Encoder Reranking =====
@article{nogueira2019passage,
    author = {Nogueira, Rodrigo and Cho, Kyunghyun},
    title = {Passage Re-ranking with {BERT}},
    journal = {arXiv preprint arXiv:1901.04085},
    year = {2019}
}

% ===== Related Systems =====
@misc{chatgpt,
    author = {OpenAI},
    title = {{ChatGPT}},
    howpublished = {\url{https://chat.openai.com/}},
    note = {Truy c\d{a}p: 15/12/2024}
}

@misc{perplexity,
    author = {Perplexity AI},
    title = {Perplexity - Ask Anything},
    howpublished = {\url{https://www.perplexity.ai/}},
    note = {Truy c\d{a}p: 15/12/2024}
}

@misc{notebooklm,
    author = {Google},
    title = {NotebookLM},
    howpublished = {\url{https://notebooklm.google/}},
    note = {Truy c\d{a}p: 15/12/2024}
}
