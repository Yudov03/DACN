# ========================
# API Keys (chon 1 trong 2 hoac ca 2)
# ========================
# OpenAI API Key
OPENAI_API_KEY=your_openai_api_key_here

# Google API Key (Gemini)
GOOGLE_API_KEY=your_google_api_key_here

# ========================
# Provider Selection
# ========================
# LLM Provider: "ollama" (local), "openai", hoac "google"
# Recommended: ollama (mien phi, chay offline)
LLM_PROVIDER=ollama

# Embedding Provider: "local" (Sentence-BERT/E5), "openai", hoac "google"
# Recommended: local (khong can API key, mien phi)
EMBEDDING_PROVIDER=local

# ========================
# Qdrant Configuration
# ========================
# Local Qdrant (Docker hoac in-memory)
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Qdrant Cloud (optional - neu dung cloud thi comment local config)
# QDRANT_URL=https://your-cluster.qdrant.io
# QDRANT_API_KEY=your_qdrant_api_key

# Collection name
COLLECTION_NAME=audio_transcripts

# ========================
# Model Configurations
# ========================
# Whisper ASR Model
WHISPER_MODEL=base
WHISPER_DEVICE=cuda

# OpenAI Models (khi dung provider=openai)
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_EMBEDDING_DIMENSION=1536
OPENAI_LLM_MODEL=gpt-4o-mini

# Google Models (khi dung provider=google)
GOOGLE_EMBEDDING_MODEL=models/text-embedding-004
GOOGLE_EMBEDDING_DIMENSION=768
GOOGLE_LLM_MODEL=gemini-2.0-flash

# Local Embedding Models (khi dung EMBEDDING_PROVIDER=local)
# Supported models:
#   - sbert (default): sentence-transformers/paraphrase-multilingual-mpnet-base-v2 (768d)
#   - e5: intfloat/multilingual-e5-base (768d)
#   - e5-large: intfloat/multilingual-e5-large (1024d)
#   - vi-sbert: keepitreal/vietnamese-sbert (768d)
LOCAL_EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-mpnet-base-v2
LOCAL_EMBEDDING_DIMENSION=768
# LOCAL_EMBEDDING_DEVICE=cuda  # or cpu (auto-detect if not set)

# ========================
# Ollama Configuration (khi dung LLM_PROVIDER=ollama)
# ========================
# Cai dat Ollama: https://ollama.ai/download
# Chay: ollama serve
# Tai model: ollama pull llama3.2
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Supported Ollama models:
#   - llama3.2 (default): Fast, 3B params
#   - llama3.2:1b: Very fast, 1B params
#   - llama3.1: Better quality, 8B params
#   - mistral: Good balance, 7B params
#   - qwen2.5: Excellent multilingual/Vietnamese, 7B params
#   - qwen2.5:3b: Fast multilingual, 3B params
#   - gemma2:2b: Very fast, 2B params
#   - phi3: Efficient reasoning, 3.8B params

# LLM Parameters
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=500

# ========================
# Chunking Parameters
# ========================
CHUNK_SIZE=500
CHUNK_OVERLAP=50
CHUNKING_METHOD=semantic

# Semantic chunking (khi method=semantic)
SEMANTIC_THRESHOLD=0.65
SEMANTIC_WINDOW_SIZE=5

# ========================
# Retrieval Parameters
# ========================
TOP_K=5
SIMILARITY_THRESHOLD=0.5
MMR_LAMBDA=0.5
