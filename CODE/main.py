"""
Main Pipeline - H·ªá th·ªëng Truy xu·∫•t Th√¥ng tin ƒêa ph∆∞∆°ng th·ª©c t·ª´ √Çm thanh
K·∫øt h·ª£p ASR, Chunking, Embedding, Vector DB v√† RAG v·ªõi LLM
"""

import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from config import Config
from modules import WhisperASR, TextChunker, TextEmbedding, VectorDatabase, RAGSystem
import argparse
import json
from typing import List, Optional


class AudioIRPipeline:
    """
    Pipeline ch√≠nh cho h·ªá th·ªëng IR t·ª´ audio
    """

    def __init__(
        self,
        whisper_model: str = None,
        embedding_model: str = None,
        vector_db_type: str = None,
        llm_model: str = None
    ):
        """
        Kh·ªüi t·∫°o pipeline

        Args:
            whisper_model: T√™n model Whisper
            embedding_model: T√™n model embedding
            vector_db_type: Lo·∫°i vector database
            llm_model: T√™n model LLM
        """
        # Use config values or override
        self.whisper_model = whisper_model or Config.WHISPER_MODEL
        self.embedding_model = embedding_model or Config.EMBEDDING_MODEL
        self.vector_db_type = vector_db_type or Config.VECTOR_DB_TYPE
        self.llm_model = llm_model or Config.LLM_MODEL

        print("=" * 80)
        print("KH·ªûI T·∫†O H·ªÜ TH·ªêNG AUDIO INFORMATION RETRIEVAL")
        print("=" * 80)

        # Initialize components
        self._init_components()

        print("\n‚úì H·ªá th·ªëng ƒë√£ s·∫µn s√†ng!")
        print("=" * 80)

    def _init_components(self):
        """Kh·ªüi t·∫°o c√°c components c·ªßa h·ªá th·ªëng"""

        # 1. ASR Module
        print("\n[1/5] Kh·ªüi t·∫°o ASR Module...")
        self.asr = WhisperASR(
            model_name=self.whisper_model,
            device=Config.WHISPER_DEVICE
        )

        # 2. Chunking Module
        print("\n[2/5] Kh·ªüi t·∫°o Chunking Module...")
        self.chunker = TextChunker(
            chunk_size=Config.CHUNK_SIZE,
            chunk_overlap=Config.CHUNK_OVERLAP,
            method=Config.CHUNKING_METHOD
        )

        # 3. Embedding Module
        print("\n[3/5] Kh·ªüi t·∫°o Embedding Module...")
        self.embedder = TextEmbedding(
            model_name=self.embedding_model
        )

        # 4. Vector Database
        print("\n[4/5] Kh·ªüi t·∫°o Vector Database...")
        self.vector_db = VectorDatabase(
            db_type=self.vector_db_type,
            db_path=Config.VECTOR_DB_DIR,
            collection_name=Config.COLLECTION_NAME,
            embedding_dimension=Config.EMBEDDING_DIMENSION
        )

        # 5. RAG System
        print("\n[5/5] Kh·ªüi t·∫°o RAG System...")
        self.rag = RAGSystem(
            vector_db=self.vector_db,
            embedder=self.embedder,
            llm_model=self.llm_model,
            api_key=Config.OPENAI_API_KEY,
            temperature=Config.LLM_TEMPERATURE,
            max_tokens=Config.LLM_MAX_TOKENS,
            top_k=Config.TOP_K
        )

    def process_audio(
        self,
        audio_path: str,
        save_intermediate: bool = True
    ) -> dict:
        """
        X·ª≠ l√Ω m·ªôt file audio: ASR -> Chunking -> Embedding -> Store

        Args:
            audio_path: ƒê∆∞·ªùng d·∫´n file audio
            save_intermediate: C√≥ l∆∞u k·∫øt qu·∫£ trung gian kh√¥ng

        Returns:
            Dict ch·ª©a th√¥ng tin x·ª≠ l√Ω
        """
        audio_path = Path(audio_path)
        print(f"\n{'=' * 80}")
        print(f"X·ª¨ L√ù AUDIO: {audio_path.name}")
        print(f"{'=' * 80}")

        # Step 1: ASR
        print("\n[Step 1/4] Transcribing audio...")
        transcript_data = self.asr.transcribe_audio(audio_path)

        if save_intermediate:
            transcript_file = Config.TRANSCRIPT_DIR / f"{audio_path.stem}_transcript.json"
            self.asr.save_transcript(transcript_data, transcript_file)

        # Step 2: Chunking
        print("\n[Step 2/4] Chunking transcript...")
        chunks = self.chunker.chunk_transcript(
            transcript_data,
            preserve_timestamps=True
        )
        print(f"‚úì ƒê√£ t·∫°o {len(chunks)} chunks")

        # Step 3: Embedding
        print("\n[Step 3/4] Creating embeddings...")
        chunks_with_embeddings = self.embedder.encode_chunks(chunks)

        # Step 4: Store in Vector DB
        print("\n[Step 4/4] Storing in vector database...")
        num_stored = self.vector_db.add_documents(chunks_with_embeddings)

        print(f"\n‚úì Ho√†n th√†nh! ƒê√£ x·ª≠ l√Ω v√† l∆∞u {num_stored} chunks t·ª´ {audio_path.name}")

        return {
            "audio_file": str(audio_path),
            "num_chunks": len(chunks),
            "num_stored": num_stored,
            "transcript_data": transcript_data
        }

    def process_audio_batch(
        self,
        audio_files: List[str],
        save_intermediate: bool = True
    ) -> List[dict]:
        """
        X·ª≠ l√Ω nhi·ªÅu file audio

        Args:
            audio_files: List ƒë∆∞·ªùng d·∫´n c√°c file audio
            save_intermediate: C√≥ l∆∞u k·∫øt qu·∫£ trung gian kh√¥ng

        Returns:
            List c√°c k·∫øt qu·∫£ x·ª≠ l√Ω
        """
        results = []

        for i, audio_file in enumerate(audio_files, 1):
            print(f"\n\n{'#' * 80}")
            print(f"FILE {i}/{len(audio_files)}")
            print(f"{'#' * 80}")

            try:
                result = self.process_audio(audio_file, save_intermediate)
                results.append(result)
            except Exception as e:
                print(f"‚úó L·ªói khi x·ª≠ l√Ω {audio_file}: {str(e)}")
                results.append({
                    "audio_file": str(audio_file),
                    "error": str(e)
                })

        return results

    def query(
        self,
        question: str,
        top_k: Optional[int] = None,
        verbose: bool = True
    ) -> dict:
        """
        Th·ª±c hi·ªán query tr√™n h·ªá th·ªëng

        Args:
            question: C√¢u h·ªèi
            top_k: S·ªë l∆∞·ª£ng chunks retrieve
            verbose: Hi·ªÉn th·ªã chi ti·∫øt

        Returns:
            Response t·ª´ RAG system
        """
        if verbose:
            print(f"\n{'=' * 80}")
            print(f"QUERY: {question}")
            print(f"{'=' * 80}")

        response = self.rag.query(
            question=question,
            top_k=top_k,
            return_sources=True
        )

        if verbose:
            self._print_response(response)

        return response

    def _print_response(self, response: dict):
        """In response m·ªôt c√°ch ƒë·∫πp m·∫Øt"""
        print("\n" + "=" * 80)
        print("ANSWER:")
        print("=" * 80)
        print(response["answer"])

        if "sources" in response and response["sources"]:
            print("\n" + "=" * 80)
            print(f"SOURCES ({len(response['sources'])} chunks):")
            print("=" * 80)

            for i, source in enumerate(response["sources"], 1):
                print(f"\n[Source {i}] Similarity: {source['similarity']:.4f}")

                if "audio_file" in source and source["audio_file"]:
                    print(f"Audio: {source['audio_file']}")

                if "start_time_formatted" in source:
                    print(f"Time: {source['start_time_formatted']} - {source['end_time_formatted']}")

                print(f"Text: {source['text'][:200]}...")

    def get_stats(self) -> dict:
        """L·∫•y th·ªëng k√™ v·ªÅ h·ªá th·ªëng"""
        stats = self.vector_db.get_collection_stats()
        return stats

    def interactive_mode(self):
        """Ch·∫ø ƒë·ªô t∆∞∆°ng t√°c v·ªõi ng∆∞·ªùi d√πng"""
        print("\n" + "=" * 80)
        print("INTERACTIVE MODE - Nh·∫≠p c√¢u h·ªèi ƒë·ªÉ truy v·∫•n")
        print("G√µ 'exit' ho·∫∑c 'quit' ƒë·ªÉ tho√°t")
        print("G√µ 'stats' ƒë·ªÉ xem th·ªëng k√™")
        print("=" * 80)

        while True:
            try:
                question = input("\nüí¨ C√¢u h·ªèi c·ªßa b·∫°n: ").strip()

                if not question:
                    continue

                if question.lower() in ["exit", "quit", "q"]:
                    print("T·∫°m bi·ªát!")
                    break

                if question.lower() == "stats":
                    stats = self.get_stats()
                    print(json.dumps(stats, indent=2, ensure_ascii=False))
                    continue

                # Query
                self.query(question)

            except KeyboardInterrupt:
                print("\n\nT·∫°m bi·ªát!")
                break
            except Exception as e:
                print(f"L·ªói: {str(e)}")


def main():
    """Main function"""
    parser = argparse.ArgumentParser(
        description="H·ªá th·ªëng Truy xu·∫•t Th√¥ng tin ƒêa ph∆∞∆°ng th·ª©c t·ª´ √Çm thanh"
    )

    parser.add_argument(
        "--mode",
        type=str,
        choices=["process", "query", "interactive"],
        default="interactive",
        help="Ch·∫ø ƒë·ªô ho·∫°t ƒë·ªông: process (x·ª≠ l√Ω audio), query (truy v·∫•n), interactive (t∆∞∆°ng t√°c)"
    )

    parser.add_argument(
        "--audio",
        type=str,
        help="ƒê∆∞·ªùng d·∫´n file audio ho·∫∑c th∆∞ m·ª•c ch·ª©a audio files"
    )

    parser.add_argument(
        "--question",
        type=str,
        help="C√¢u h·ªèi ƒë·ªÉ query"
    )

    parser.add_argument(
        "--top-k",
        type=int,
        default=None,
        help="S·ªë l∆∞·ª£ng chunks retrieve"
    )

    args = parser.parse_args()

    # Initialize pipeline
    pipeline = AudioIRPipeline()

    # Execute based on mode
    if args.mode == "process":
        if not args.audio:
            print("L·ªói: C·∫ßn ch·ªâ ƒë·ªãnh --audio ƒë·ªÉ x·ª≠ l√Ω")
            return

        audio_path = Path(args.audio)

        if audio_path.is_file():
            # Process single file
            pipeline.process_audio(str(audio_path))
        elif audio_path.is_dir():
            # Process all audio files in directory
            audio_files = list(audio_path.glob("*.mp3")) + \
                         list(audio_path.glob("*.wav")) + \
                         list(audio_path.glob("*.m4a"))

            if not audio_files:
                print(f"Kh√¥ng t√¨m th·∫•y file audio trong {audio_path}")
                return

            pipeline.process_audio_batch([str(f) for f in audio_files])
        else:
            print(f"Kh√¥ng t√¨m th·∫•y: {audio_path}")

    elif args.mode == "query":
        if not args.question:
            print("L·ªói: C·∫ßn ch·ªâ ƒë·ªãnh --question ƒë·ªÉ query")
            return

        pipeline.query(args.question, top_k=args.top_k)

    else:  # interactive
        pipeline.interactive_mode()


if __name__ == "__main__":
    main()
